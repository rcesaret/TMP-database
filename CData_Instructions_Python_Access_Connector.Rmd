---
title: "Untitled"
author: "Rudolf Cesaretti"
date: "2025-01-12"
output: html_document
---


# CData Python Connector for Microsoft Access



## 1. Getting Started

### 1.1. Establishing a Connection

The objects available within our connector are accessible from the "cdata.access" module. To use the module's objects directly:

First, import the module as follows:  
    
    `import cdata.access` `as` `mod`
    
Then, to establish a connection string, call the **connect()** method from the connector object using an appropriate connection string, such as:  
    
    `mod.connect(``"DataSource=C:\\My.accdb"``)`
    

#### 1.1.1. Connecting to Microsoft Access

To connect to Microsoft Access, set <u>DataSource</u> to the full path (including filename) of a Microsoft Access database file. For example, C:\\Users\\Public\\Documents\\MyDatabase.accdb.


Java Native Interface (JNI) is a standard programming interface for writing Java native methods and embedding the Java virtual machine into native applications.

The connector leverages the JNI for improved performance on Mac and Linux.

### 1.2. Configure the Config INI File

The Linux and Mac editions of the Microsoft Access python connector are configured with an ini file. This file is used to set several parameters, including JNI behavior. This file is to be located in:  

`{path_to_distribution_site-packages}/cdata/config.ini`

Ensure that any configuration properties you set in the ini file fall under the following section name (adjust the 311 number if you are using an different python version from 3.11):

-   For Linux:  
    
    `[access.cpython-311-x86_64-linux-gnu.so]`
    
-   For Mac:  
    
    `[access.cpython-311-darwin.so]`

#### 1.2.1. Configuring JNI

Configure the JNI connector's behavior by editing the properties in the connector's config.ini file. The connector can be configured as follows:

-   LOGFILE: Set this the same way as the CDATA\_LOGFILE envrionment variable below.
-   JAVA\_HOME: Configure the path to the JVM library location used to launch the JVM.
-   CLASS\_PATH: Use a colon-separated list to configure the paths to the third-party jar libraries.

#### 1.2.2. Configure Environment Variables

Additionally, set the following environment variables:

-   CDATA\_JAVA\_HOME: Configure the path to the JVM library location used to launch the JVM.
-   CDATA\_JVM\_OPTIONS: Place JVM options here.
-   CDATA\_LOGFILE: Set this in the following scheme: <SCHEME>://<TAG>\[|<LEVEL>\]
    -   SCHEME: The options are STDOUT, FILE.
        -   STDOUT: Both the native wrapper and odbc core log into stdout. The <u>Logfile</u> and <u>Verbosity</u> properties can override the behavior of ODBC core.
        -   FILE: The native wrapper logs into <FILENAME> while the odbc core logs into <FILENAME>.driver.log. The <u>Logfile</u> and <u>Verbosity</u> properties can override the behavior of ODBC core.
    -   TAG
        -   For STDOUT, set this to 1. For FILE, set this to the filename.
    -   LEVEL
        -   Set to one of: FATAL | ERROR | WARNING | INFO | DEBUG

The following are some examples of this syntax:

-   STDOUT://1|DEBUG
-   FILE:///tmp/my\_py.log|DEBUG


### 1.3. Changelog

#### 1.3.1. General Changes

<table><tbody><tr><td><b>Date</b></td><td><b>Build<br>Number</b></td><td><b>Change<br>Type</b></td><td><b>Description</b></td></tr><tr><td>06/05/2024</td><td>8922</td><td>Python</td><td><b>Added</b><br><ul><li>Added support for Python 3.12.</li></ul></td></tr><tr><td>05/09/2024</td><td>8895</td><td>General</td><td><b>Changed</b><br><ul><li>The ROUND function previously did not accept negative precision values. That feature has now been restored.</li></ul></td></tr><tr><td>03/15/2024</td><td>8840</td><td>General</td><td><b>Added</b><br><ul><li>Created a new SQL function called STRING_COMPARE that provides java's String.compare() ability to SQL queries. Returns a number representative of the compared value of two strings</li></ul></td></tr><tr><td>11/29/2023</td><td>8733</td><td>General</td><td><b>Changed</b><br><ul><li>The ROUND function doesn't accept the negative precision values anymore.</li></ul><br><b>Changed</b><br><ul><li>The returning types of the FDMonth, FDQuarter, FDWeek, LDMonth, LDQuarter, LDWeek functions are changed from Timestamp to Date.</li><li>The return type of the ABS function will be consistent with the parameter value type.</li></ul></td></tr><tr><td>11/28/2023</td><td>8732</td><td>General</td><td><b>Added</b><br><ul><li>Added the HMACSHA256 formatter to allow for secrets to be decoded if it is in base64 format</li></ul></td></tr><tr><td>08/29/2023</td><td>8641</td><td>Python</td><td><b>Added</b><br><ul><li>Added support for SQLAlchemy 2.0.</li></ul></td></tr><tr><td>05/19/2023</td><td>8539</td><td>Python</td><td><b>Added</b><br><ul><li>Added support for Python 3.11 on Windows, Linux and Mac.</li></ul></td></tr><tr><td>05/16/2023</td><td>8536</td><td>Python</td><td><b>Removed</b><br><ul><li>Removed support for Python 3.7 on Windows and Linux</li></ul></td></tr><tr><td>04/25/2023</td><td>8515</td><td>General</td><td><b>Removed</b><br><ul><li>Removed support for the SELECT INTO CSV statement. The core code doesn't support it anymore.</li></ul></td></tr><tr><td>01/21/2023</td><td>8421</td><td>Microsoft Access</td><td><b>Added</b><br><ul><li>Added support for the Large Number and Date/Time Extended data types of Access 2016 and 2019.</li></ul></td></tr><tr><td>12/02/2022</td><td>8371</td><td>Microsoft Access</td><td><b>Added</b><br><ul><li>Added optional possibility to query data from the system tables in the read-only mode.</li></ul></td></tr><tr><td>11/15/2022</td><td>8354</td><td>Python</td><td><b>Changed</b><br><ul><li>Updated embedded JRE to jre8u345-b01(Linux x64 / MacOS x64) and jre-17.0.5+8(MacOS aarch64).</li></ul></td></tr><tr><td>05/24/2022</td><td>8179</td><td>Microsoft Access</td><td><b>Changed</b><br><ul><li>Changed provider name to Microsoft Access.</li></ul></td></tr><tr><td>05/18/2022</td><td>8173</td><td>Python</td><td><b>Added</b><br><ul><li>Added support for Python 3.10 on Windows, Linux, and Mac</li><li>Added support for Python 3.9 on Mac</li><li>Added support for Mac M1</li></ul><br><b>Removed</b><br><ul><li>Removed support for Python 3.6 on Windows and Linux</li></ul></td></tr><tr><td>09/02/2021</td><td>7915</td><td>General</td><td><b>Added</b><br><ul><li>Added support for the STRING_SPLIT table-valued function in the CROSS APPLY clause.</li></ul></td></tr><tr><td>07/23/2021</td><td>7874</td><td>General</td><td><b>Changed</b><br><ul><li>Updated the Literal Function Names for relative date/datetime functions. Previously, relative date/datetime functions resolved to a different value when used in the projection as opposed to the predicate. For example: SELECT LAST_MONTH() AS lm, Col FROM Table WHERE Col &gt; LAST_MONTH(). Formerly, the two LAST_MONTH() methods would resolve to different datetimes. Now, they will match.</li><li>As a replacement for the previous behavior, the relative date/datetime functions in the criteria may have an 'L' appended to them. For example: WHERE col &gt; L_LAST_MONTH(). This will continue to resolve to the same values that were previously calculated in the criteria. Note that the "L_" prefix will only work in the predicate - it not available for the projection.</li></ul></td></tr><tr><td>04/25/2021</td><td>7785</td><td>General</td><td><b>Added</b><br><ul><li>Added support for handling client side formulas during insert / update. For example: UPDATE Table SET Col1 = CONCAT(Col1, " - ", Col2) WHERE Col2 LIKE 'A%'</li></ul></td></tr><tr><td>04/23/2021</td><td>7783</td><td>General</td><td><b>Changed</b><br><ul><li>Updated how display sizes are determined for varchar primary key and foreign key columns so they will match the reported length of the column.</li></ul></td></tr><tr><td>04/16/2021</td><td>7776</td><td>General</td><td><b>Added</b><br><ul><li>Non-conditional updates between two columns is now available to all drivers. For example: UPDATE Table SET Col1=Col2</li></ul></td></tr><tr><td>04/16/2021</td><td>7776</td><td>General</td><td><b>Changed</b><br><ul><li>Reduced the length to 255 for varchar primary key and foreign key columns.</li></ul><br><b>Changed</b><br><ul><li>Updated index naming convention to avoid duplicates.</li></ul></td></tr></tbody></table>


## 2. Using the Connector

This section provides a walk-through for writing Microsoft Access data access code in Python script.

For more information on the available data source entities and how to query them with SQL, see [Data Model](https://cdn.cdata.com/help/DCK/py/pg_datamodel.htm).

For information on how to deploy the connector and configure the connection to Microsoft Access, see [Package Installation](https://cdn.cdata.com/help/DCK/py/pg_pyinstallation.htm) and [Establishing a Connection](https://cdn.cdata.com/help/DCK/py/pg_connectionpy.htm).

For information on how to connect with the access.connector module and its related classes, see [Connecting](https://cdn.cdata.com/help/DCK/py/pg_usagescriptconnectpy.htm).

The connection's cursor object is used to directly execute SQL queries. For information on how to execute SELECT statements and process the returned result sets, see [Querying Data](https://cdn.cdata.com/help/DCK/py/pg_usagescriptquerypy.htm). For information on to modify the data in Microsoft Access with INSERT, UPDATE, and DELETE statements, see [Modifying Data](https://cdn.cdata.com/help/DCK/py/pg_usagescriptupdatepy.htm) .

You can call stored procedures by using the EXECUTE statement. For further information, see [Calling Stored Procedures](https://cdn.cdata.com/help/DCK/py/pg_usagescriptprocpy.htm).

For information about how to modify several rows of Microsoft Access data at once using parameterized INSERT, UPDATE, and DELETE statements, see [Batch Processing](https://cdn.cdata.com/help/DCK/py/pg_usagescriptbatchpy.htm).


### 2.1. Connecting

#### 2.1.1. Connecting with the cdata.access Module:

The connector's module is used directly to establish a connection with the data source. It does this by using a connection string as its argument. For example:

`import cdata.access` `as` `mod`

`conn = mod.connect(``"DataSource=C:\\My.accdb"``)`

Once the connection is created, you can use it to execute subsequent SQL queries.

### 2.2. Querying Data

After connecting as described in [Connecting](https://cdn.cdata.com/help/DCK/py/pg_usagescriptconnectpy.htm), you can use the open connection to execute SQL statements.

#### 2.2.1. Executing Queries

To execute SQL statements that return data, use the **execute()** method. Once a query is executed, the result set is fetched from the cursor. This result set can then be iterated over to process the records individually.

For example:  

`cur = conn.execute(``"SELECT ShipName, ShipCity FROM Orders"``)`

`rs = cur.fetchall()`

`for` `row` `in` `rs:`

    `print(row)`

#### 2.2.2. Parameterized Queries

Various Python collections, such as arrays and tuples, can act as additional arguments for the **execute()** method. This enables you to parameterize the queries executed and help to prevent SQL Injection.

For example:  

`cmd =` `"SELECT ShipName, ShipCity FROM Orders WHERE ShipCountry = ?"`

`params` `= [``"USA"``]`

`cur = conn.execute(cmd,` `params``)`

`rs = cur.fetchall()`

`for` `row` `in` `rs:`

    `print(row)`


### 2.3. Modifying Data

The connection is also used to issue INSERT, UPDATE, and DELETE commands to the data source. Parameters can be used with these statements if desired.

Note that the connector does not support transactions. As with normal write operations, all SQL statements executed by this connector affect the data source immediately. Call the connection's **commit()** method following the execution.

#### 2.3.1. Insert

The following example adds a new record to the table:

`cmd =` `"INSERT INTO Orders (ShipName, ShipCity) VALUES (?, ?)"`

`params` `= [``"Raleigh"``,` `"New York"``]`

`cur = conn.execute(cmd,` `params``)`

`print(``"Records affected: "``, cur.rowcount)`

#### 2.3.2. Update

The following example modifies an existing record in the table:

`cmd =` `"UPDATE Orders SET ShipCity = ? WHERE Id = ?"`

`params` `= [``"New York"``,` `"10261"``]`

`cur = conn.execute(cmd,` `params``)`

`print(``"Records affected: "``, cur.rowcount)`

#### 2.3.3. Delete

The following example removes an existing record from the table:  

`cmd =` `"DELETE FROM Orders WHERE Id = ?"`

`params` `= [``"10261"``]`

`cur = conn.execute(cmd,` `params``)`

`print(``"Records affected: "``, cur.rowcount)`




### 2.4. Calling Stored Procedures

You can execute stored procedures using either the **execute()** or **callproc()** method of the connection.

#### 2.4.1. Calling Stored Procedures Using Execute()

When you call stored procedures by issuing EXECUTE commands, the stored procedure arguments are parameterized. For example:

`cmd =` `"EXECUTE SelectEntries ObjectName = ?"`

`params` `= [``"Account"``]`

`conn.execute(cmd,` `params``)`

#### 2.4.2. Calling Stored Procedures Using Callproc()

When you call stored procedured by issuing the **callproc()** method, the stored procedure arguments are a procedure name and a list of parameters. For example:

`cur = conn.cursor()`

`params` `= [``"Account"``]`

`cur.callproc(``"SelectEntries"``,` `params``)`



### 2.5. Batch Processing

This Python connector also supports writing to the data source via batch processing, using the cursor object's **executemany()** method. This requires both a SQL statement string and a data frame of values that act as a series of parameters for executing the SQL statement.

Note that the connector does not support transactions. As with normal write operations, all SQL statements executed by this connector affect the data source immediately. Call the connection's **commit()** method following the execution.

#### 2.5.1. Insert

The following example adds new records to the table:

`cur = conn.cursor()`

`cmd =` `"INSERT INTO Orders (ShipName, ShipCity) VALUES (?, ?)"`

`params` `= [[``"Raleigh"``,` `"New York"``], [``"Raleigh"``,` `"New York"``]]`

`cur.executemany(cmd,` `params``)`

`print(``"Records affected: "``, cur.rowcount)`

#### 2.5.2. Update

The following example modifies existing records in the table:

`cur = conn.cursor()`

`cmd =` `"UPDATE Orders SET ShipCity = ? WHERE Id = ?"`

`params` `= [[``"New York"``,` `"10261"``], [``"New York"``,` `"10261"``]]`

`cur.executemany(cmd,` `params``)`

`print(``"Records affected: "``, cur.rowcount)`

#### 2.5.3. Delete

The following example removes existing records from the table:

`cur = conn.cursor()`

`cmd =` `"DELETE FROM Orders WHERE Id = ?"`

`params` `= [[``"10261"``], [``"10261"``]]`

`cur.executemany(cmd,` `params``)`

`print(``"Records affected: "``, cur.rowcount)`

## 3. Integration with other Python Libraries

The connector is integrated with other tools and packages within Python.

The CData Python Connector for Microsoft Access includes a **Dialect** class that enables integration with SQLAlchemy. Bear in mind that several aspects of connector functionality are not currently supported in SQLAlchemy 2.0 or above. If necessary, downgrade SQLAlchemy to version 1.4 or 1.3 before using this connector.

The following sections detail various aspects of this integration:

### 3.1. Connecting From SQLAlchemy

To construct a URL with which SQLAlchemy loads and uses the appropriate connector automatically, see [Connecting](https://cdn.cdata.com/help/DCK/py/pg_usageORMconnectpy.htm)

#### 3.1.1. Connecting With a Dialect URL

Establishing a connection using SQLAlchemy requires a specific URL format.

`from sqlalchemy import create_engine`

`engine = create_engine(``"cdata_access:///?DataSource=C:\\My.accdb"``)`

For SQLAlchemy 2.0, the dialect name is **access\_2**. To establish a connection, use the following URL format:  

`from sqlalchemy import create_engine`

`engine = create_engine(``"quickbooks_2:///?User=test;Password=test;URL=http://localhost:8166;"``)`

#### 3.1.2. Reflecting Metadata With SQLAlchemy

To learn how to model Microsoft Access tables with mapped classes, see [Reflecting Metadata](https://cdn.cdata.com/help/DCK/py/pg_usageORMreflectpy.htm).

SQLAlchemy can act as an Object-relational Map (ORM). This enables you to treat records of a database table as instantiable records. To leverage this functionality, you must reflect the underlying metadata in one of the following ways.

**Note:** The following examples employ SQLAlchemy 1.4.

##### 3.1.2.1. Modeling Data Using a Mapping Class

Use "sqlalchemy.ext.declarative.declarative\_base" to declare a mapping class for the table you wish to model in the ORM. A known table in the data model is modeled either partially or completely, as shown in the following example:

`from sqlalchemy.ext.declarative import declarative_base`

`Base = declarative_base()`

`class` `Orders(Base):`

    `__tablename__ =` `"Orders"`

    `Id = Column(String, primary_key=True)`

    `ShipName = Column(String)`

    `ShipCity = Column(String)`

##### 3.1.2.2. Automatically Reflecting Metadata

Rather than mapping tables manually, SQLAlchemy can discover the metadata for one or more tables automatically. To accomplish this across the entire data model, use automap\_base:

`from sqlalchemy import MetaData`

`from sqlalchemy.ext.automap import automap_base`

`meta = MetaData()`

`abase = automap_base(metadata=meta)`

`abase.prepare(autoload_with=engine)`

`Orders = abase.classes.Orders`

You can also reflect a single table with an inspector. When reflecting this way, providing a list of specific columns to map is optional:  

`from sqlalchemy import MetaData, Table`

`from sqlalchemy import inspect`

`meta = MetaData()`

`insp = inspect(engine)`

`Orders_table = Table(``"Orders"``, meta)`

`insp.reflect_table(Orders_table, [``"Id"``,``"ShipCity"``])`

#### 3.1.3. Querying Data From SQLAlchemy

To learn how to use mapped classes to query the associated tables, see [Querying Data](https://cdn.cdata.com/help/DCK/py/pg_usageORMquerypy.htm).

After you use the steps in [Connecting](https://cdn.cdata.com/help/DCK/py/pg_usageORMconnectpy.htm) to connect, and use one of the methods in [Reflecting Metadata](https://cdn.cdata.com/help/DCK/py/pg_usageORMreflectpy.htm) to reflect some of the metadata, you can use a session object to query data.

##### 3.1.3.1. Querying Data

###### Querying Data Using the Query Method

If the mapping class has been prepared, use it with a session object to query the data source. After binding the engine to the session, provide the mapping class to the session's query method.

For example:  

`engine = create_engine(``"cdata_access:///?DataSource=C:\\My.accdb"``)`

`factory = sessionmaker(bind=engine)`

`session = factory()`

`for` `instance` `in` `session.query(Orders).filter_by(ShipCountry=``"USA"``):`

    `print(``"Id: "``, instance.Id)`

    `print(``"ShipName: "``, instance.ShipName)`

    `print(``"ShipCity: "``, instance.ShipCity)`

    `print(``"---------"``)`

###### Querying Data Using the Execute Method

The session object can also run the query with the **execute()** method alongside the appropriate Table object. Assuming you have an active session, the following is just as viable:

`Orders_table = Orders.metadata.tables[``"Orders"``]`

`for` `instance` `in` `session.execute(Orders_table.select().where(Orders_table.c.ShipCountry ==` `"USA"``)):`

    `print(``"Id: "``, instance.Id)`

    `print(``"FullName: "``, instance.Name)`

    `print(``"City: "``, instance.BillingCity)`

    `print(``"---------"``)`

##### 3.1.3.2. Executing JOINs

###### Implicit Joining

If mapped classes of related Microsoft Access objects have a singular foreign key relationship, the classes are implicitly joined. After importing the necessary objects, a relationship is established between your two mapped classes, as in the example below:

`from sqlalchemy.ext.declarative import declarative_base`

`from sqlalchemy import Column, String, Integer, DateTime, ForeignKey`

`from sqlalchemy.orm import sessionmaker, relationship`

`Base = declarative_base()`

`class` `Contact(Base):`

    `__tablename__ =` `"Contact"`

    `Id = Column(Integer, primary_key=True)`

    `Name = Column(String)`

    `Email = Column(String)`

    `BirthDate = Column(DateTime)`

    `AccountId = Column(String, ForeignKey(``"Account.Id"``))`

    `Account_Link = relationship(``"Account"``, back_populates=``"Contact_Link"``)`

`class` `Account(Base):`

    `__tablename__ =` `"Account"`

    `Id = Column(String, primary_key=True)`

    `Name = Column(String)`

    `BillingCity = Column(String)`

    `NumberOfEmployees = Column(Integer)`

    `Contact_Link = relationship(``"Contact"``, order_by=Contact.Id, back_populates=``"Account_Link"``)`

Once the relationship is established, the tables are queried simultaneously using the session's **query()** method. For example:  

`rs = session.query(Account, Contact).filter(Account.Id == Contact.AccountId)`

`for` `Ac, Ct` `in` `rs:`

  `print(``"AccountId: "``, Ac.Id)`

  `print(``"AccountName: "``, Ac.Name)`

  `print(``"ContactId: "``, Ct.Id)`

  `print(``"ContactName: "``, Ct.Name)`

###### Other Join Forms

In situations where mapped classes have either no foreign keys or multiple foreign keys, you may need different forms of the JOIN query to accommodate them. Using the earlier classes as examples, the following JOIN queries are possible as well:

-   Explicit condition (necessary if there are no foreign keys in your mapped classes):  
    
    `rs = session.query(Account, Contact).join(Contact, Account.Id == Contact.AccountId)`
    
    `for` `Ac, Ct` `in` `rs:`
    
-   Left-to-right relationship:  
    
    `rs = session.query(Account, Contact).join(Account.Contact_Link)`
    
    `for` `Ac, Ct` `in` `rs:`
    
-   Left-to-right relationship with explicit target:  
    
    `rs = session.query(Account, Contact).join(Contact, Account.Contact_Link)`
    
    `for` `Ac, Ct` `in` `rs:`
    
-   String form of a left-to-right relationship:  
    
    `rs = session.query(Account, Contact).join(``"Contact_Link"``)`
    
    `for` `Ac, Ct` `in` `rs:`


##### 3.1.3.3. Other SQL Clauses

SQLAlchemy ORM also exposes support for other clauses in SQL, such as ORDER BY, GROUP BY, LIMIT, and OFFSET. All of these are supported by this connector:

###### ORDER BY

The following example sorts by a specified column using the session object's query() method:

`rs = session.query(Orders).order_by(Orders.Freight)`

`for` `instance` `in` `rs:`

    `print(``"Id: "``, instance.Id)`

    `print(``"ShipName: "``, instance.ShipName)`

    `print(``"ShipCity: "``, instance.ShipCity)`

    `print(``"---------"``)`

You can also use the session object's **execute()** method perform an ORDER BY. For example:  

`rs = session.execute(Orders_table.select().order_by(Orders_table.c.Freight))`

`for` `instance` `in` `rs:`

###### GROUP BY

The following example uses the session object's **query()** method to group records with a specified column:

`rs = session.query(func.count(Orders.Id).label(``"CustomCount"``), Orders.ShipName).group_by(Orders.ShipName)`

`for` `instance` `in` `rs:`

    `print(``"Count: "``, instance.CustomCount)`

    `print(``"ShipName: "``, instance.ShipName)`

    `print(``"---------"``)`

You can also use the session object's **execute()** method to perform a GROUP BY:  

`rs = session.execute(Orders_table.select().with_only_columns([func.count(Orders_table.c.Id).label(``"CustomCount"``), Orders_table.c.ShipName]).group_by(Orders_table.c.ShipName))`

`for` `instance` `in` `rs:`

###### LIMIT and OFFSET

The following example uses the session object's **query()** method to skip the first 100 records and fetch the following 25:

`rs = session.query(Orders).limit(25).offset(100)`

`for` `instance` `in` `rs:`

    `print(``"Id: "``, instance.Id)`

    `print(``"ShipName: "``, instance.ShipName)`

    `print(``"ShipCity: "``, instance.ShipCity)`

    `print(``"---------"``)`

You can also use the session object's **execute()** method to set a LIMIT or OFFSET:  

`rs = session.execute(Orders_table.select().limit(25).offset(100))`

`for` `instance` `in` `rs:`


##### 3.1.3.4. Aggregate Functions

Certain aggregate functions can also be used within SQLAlchemy by using the _func_ module.

To import this module, execute:  

`from sqlalchemy.sql import func`

Once _func_ is imported, the following aggregate functions are available:

###### COUNT

The following example counts the number of records in a set of groups using the session object's **query()** method.

`rs = session.query(func.count(Orders.Id).label(``"CustomCount"``), Orders.ShipName).group_by(Orders.ShipName)`

`for` `instance` `in` `rs:`

    `print(``"Count: "``, instance.CustomCount)`

    `print(``"ShipName: "``, instance.ShipName)`

    `print(``"---------"``)`

You can also execute COUNT using the session object's **execute()** method:  

`rs = session.execute(Orders_table.select().with_only_columns([func.count(Orders_table.c.Id).label(``"CustomCount"``), Orders_table.c.ShipName])group_by(Orders_table.c.ShipName))`

`for` `instance` `in` `rs:`

###### SUM

This example calculates the cumulative amount of a numeric column in a set of groups.  

`rs = session.query(func.sum(Orders.Freight).label(``"CustomSum"``), Orders.ShipName).group_by(Orders.ShipName)`

`for` `instance` `in` `rs:`

    `print(``"Sum: "``, instance.CustomSum)`

    `print(``"ShipName: "``, instance.ShipName)`

    `print(``"---------"``)`

You can also invoke SUM using the session object's **execute()** method.  

`rs = session.execute(Orders_table.select().with_only_columns([func.sum(Orders_table.c.Freight).label(``"CustomSum"``), Orders_table.c.ShipName]).group_by(Orders_table.c.ShipName))`

`for` `instance` `in` `rs:`

###### AVG

This example uses the session object's **query()** method to calculate the average amount of a numeric column in a set of groups:

`rs = session.query(func.avg(Orders.Freight).label(``"CustomAvg"``), Orders.ShipName).group_by(Orders.ShipName)`

`for` `instance` `in` `rs:`

    `print(``"Avg: "``, instance.CustomAvg)`

    `print(``"ShipName: "``, instance.ShipName)`

    `print(``"---------"``)`

You can also use the session object's **execute()** method to invoke AVG:  

`rs = session.execute(Orders_table.select().with_only_columns([func.avg(Orders_table.c.Freight).label(``"CustomAvg"``), Orders_table.c.ShipName]).group_by(Orders_table.c.ShipName))`

`for` `instance` `in` `rs:`

###### MAX and MIN

This example finds the maximum value and minimum value of a numeric column in a set of groups.

`rs = session.query(func.max(Orders.Freight).label(``"CustomMax"``), func.min(Orders.Freight).label(``"CustomMin"``), Orders.ShipName).group_by(Orders.ShipName)`

`for` `instance` `in` `rs:`

    `print(``"Max: "``, instance.CustomMax)`

    `print(``"Min: "``, instance.CustomMin)`

    `print(``"ShipName: "``, instance.ShipName)`

    `print(``"---------"``)`

You can also use the session object's **execute()** method to invoke MAX and MIN:  

`rs = session.execute(Orders_table.select().with_only_columns([func.max(Orders_table.c.Freight).label(``"CustomMax"``), func.min(Orders_table.c.Freight).label(``"CustomMin"``), Orders_table.c.ShipName]).group_by(Orders_table.c.ShipName))`

`for` `instance` `in` `rs:`





#### 3.1.4. Modifying Data From SQLAlchemy

The connector provides INSERT/UPDATE/DELETE functionality in SQLAlchemy. To learn how to call the session's **execute()** method to affect the data in the data source, see [Modifying Data](https://cdn.cdata.com/help/DCK/py/pg_usageORMupdatepy.htm).

Commands can be executed individually by the session with a call to "execute()".

##### 3.1.4.1. Obtaining the Table Object

The query supplied to this method is constructed using the associated Table object of a mapped class. This Table object is obtained from the mapped class's metadata field, as below:  

`Orders_table = Orders.metadata.tables[``"Orders"``]`

Once the table object is obtained, the write operations are executed in the following ways. The queries are executed immediately without the need for a call to "commit()":

##### 3.1.4.2. Insert

The following example adds a new record to the table:  

`session.execute(Orders_table.insert(), {``"ShipName"``:` `"Raleigh"``,` `"ShipCity"``:` `"New York"``})`

##### 3.1.4.3. Update

The following example modifies an existing record in the table:  

`session.execute(Orders_table.update().where(Orders_table.c.Id ==` `"10261"``).values(ShipName=``"Raleigh"``, ShipCity=``"New York"``))`

##### 3.1.4.4. Delete

The following example removes an existing record from the table:  

`session.execute(Orders_table.delete().where(Orders_table.c.Id ==` `"10261"``))`

### 3.2. Connecting From Pandas

#### 3.2.1. From Pandas

When combined with the connector, Pandas can be used to generate data frames that contain your Microsoft Access data. Once created, a data frame can be passed to various other Python packages.

#### 3.2.2. Connecting

Pandas relies on an SQLAlchemy engine to execute queries. Before you can use Pandas you must import it:

`import pandas` `as` `pd`

`from sqlalchemy import create_engine`

`engine = create_engine(``"cdata_access:///?DataSource=C:\\My.accdb"``)`

#### 3.2.3. Querying Data

In Pandas, SELECT queries are provided in a call to the **read\_sql()** method, alongside a relevant connection object. Pandas executes the query on that connection, and returns the results in the form of a data frame, which can be used for a variety of purposes.

`df = pd.read_sql(``""``"`

    `SELECT`

       `ShipName,`

       `ShipCity,`

     `$exNumericCol;`

    `FROM Orders;``""``", engine)`

`print(df)`

#### 3.2.4. Modifying Data

To insert new records into a table, create a new data frame, and define its fields accordingly. When that is done, call **to\_sql()** on the data frame to perform the INSERT operation with the connector, as shown in the example below. You must set the "if \_exists" argument to "append" to prevent Pandas from attempting building the table from scratch. To prevent Pandas from writing the data frame index as a column, set **index=False**.

`df = pd.DataFrame({``"ShipName"``: [``"Raleigh"``],` `"ShipCity"``: [``"New York"``]})`

`df.to_sql(``"Orders"``, con=engine, if_exists=``"append"``, index=False)`


### 3.3. Connecting From Matplotlib

Matplotlib contains a number of tools that can graphically model Microsoft Access data after being fed a data frame [From Pandas](https://cdn.cdata.com/help/DCK/py/pg_usagetoolspandaspy.htm).

#### 3.3.1. Using PyPlot

Before any Matplotlib tool, such as pyplot, can be used, it must be imported:

`from matplotlib import pyplot` `as` `plt`

Once a Pandas data frame is obtained, it can be used to create a plot visualizing Microsoft Access data. For example, the following plot generates and displays a bar graph relating ShipName and Freight values:  

`df.plot(kind=``"bar"``, x=``"ShipName"``, y=[``"Freight"``])`

`plt.show()`



### 3.4. Connecting From Petl


The connector can be used to create ETL applications and pipelines for CSV data in Python using Petl.

#### 3.4.1. Install Required Modules

Install the Petl modules using the pip utility.

#### 3.4.2. Connecting

After you import the modules, including the CData Python Connector for Microsoft Access, you can use the connector's **connect** function to create a connection using a valid Microsoft Access connection string. If you prefer not to use a direct connection, you can use a SQLAlchemy engine.

`import petl` `as` `etl`

`import cdata.access` `as` `mod`

`cnxn = mod.connect(``"DataSource=C:\\My.accdb"``)`

#### 3.4.3. Extract, Transform, and Load the Microsoft Access Data

Create a SQL query string and store the query results in a DataFrame.

`sql =` `"SELECT   ShipName, ShipCity FROM Orders "`

`table1 = etl.fromdb(cnxn,sql)`

##### 3.4.3.1. Loading Data

With the query results stored in a DataFrame, you can load your data into any supported Petl destination. The following example loads the data into a CSV file.

`etl.tocsv(table1,``'output.csv'``)`

##### 3.4.3.2. Modifying Data

Insert new rows into Microsoft Access tables using Petl's appenddb function.

`table1 = [[``'ShipName'``,``'ShipCity'``],[``'Raleigh'``,``'New York'``]]`

`etl.appenddb(table1,cnxn,``'Orders'``)`


## 4. Schema Discovery

### 4.1. Tables and Views

The connector possesses system tables that are used to discover the tables and views available in the data model. Of these system tables, "sys\_tables" and "sys\_views" are used to fetch information about the available tables and views respectively:

#### 4.1.1. Tables


`import cdata.access` `as` `mod`

`conn = mod.connect(``"DataSource=C:\\My.accdb"``)`

`cur = conn.cursor()`

`cmd =` `"SELECT * FROM sys_tables"`

`cur.execute(cmd)`

`rs = cur.fetchall()`

`for` `row` `in` `rs:`

    `print(row)`


#### 4.1.2. Views

  
`import cdata.access` `as` `mod`

`conn = mod.connect(``"DataSource=C:\\My.accdb"``)`

`cur = conn.cursor()`

`cmd =` `"SELECT * FROM sys_views"`

`cur.execute(cmd,` `params``)`

`rs = cur.fetchall()`

`for` `row` `in` `rs:`

    `print(row)`

### 4.2. Columns

The available columns for any given table are fetched from a system table called "sys\_tablecolumns". A specific table name is provided in the WHERE criteria to restrict the table from which the column information is fetched:  

`import cdata.access` `as` `mod`

`conn = mod.connect(``"DataSource=C:\\My.accdb"``)`

`cur = conn.cursor()`

`cmd =` `"SELECT * FROM sys_tablecolumns WHERE TableName = 'Orders'"`

`cur.execute(cmd)`

`rs = cur.fetchall()`

`for` `row` `in` `rs:`

    `print(row)`




### 4.3. Procedures

#### 4.3.1. Procedures

A system table called "sys\_procedures" is queried to obtain the available stored procedures that are executed:

`import cdata.access` `as` `mod`

`conn = mod.connect(``"DataSource=C:\\My.accdb"``)`

`cur = conn.cursor()`

`cmd =` `"SELECT * FROM sys_procedures"`

`cur.execute(cmd)`

`rs = cur.fetchall()`

`for` `row` `in` `rs:`

    `print(row)`


#### 4.3.2. Parameters

The input parameters of any stored procedure are similarly obtained from the "sys\_procedureparameters" system table:

`import cdata.access` `as` `mod`

`conn = mod.connect(``"DataSource=C:\\My.accdb"``)`

`cur = conn.cursor()`

`cmd =` `"SELECT * FROM sys_procedureparameters WHERE ProcedureName = 'SelectEntries'"`

`cur.execute(cmd)`

`rs = cur.fetchall()`

`for` `row` `in` `rs:`

    `print(row)`


## 5. Advanced Features

This section details a selection of advanced features of the Microsoft Access connector.

### 5.1. SSL Configuration

#### 5.1.1. Customizing the SSL Configuration

By default, the connector attempts to negotiate TLS with the server. The server certificate is validated against the default system trusted certificate store. You can override how the certificate gets validated using the `SSLServerCert` connection property.

To specify another certificate, see the `SSLServerCert` connection property.


### 5.2. Firewall and Proxy

#### 5.2.1. Connecting Through a Firewall or Proxy

Set the following properties:

-   To use a proxy-based firewall, set `FirewallType`, `FirewallServer`, and `FirewallPort.`
-   To tunnel the connection, set `FirewallType` to `TUNNEL`.
-   To authenticate, specify `FirewallUser` and `FirewallPassword`.
-   To authenticate to a `SOCKS` proxy, additionally set `FirewallType` to `SOCKS5`.

### 5.3. Logging

Capturing connector logging can be very helpful when diagnosing error messages or other unexpected behavior.

#### 5.3.1. Basic Logging

To begin capturing connector logging, set these properties:

-   <u>Logfile</u>: A filepath that designates the name and location of the log file.
-   <u>Verbosity</u>: A numerical value (1-5) that determines the amount of detail in the log. See the page in the Connection Properties section for an explanation of the five levels.
-   <u>MaxLogFileSize</u>: When the limit is hit, a new log is created in the same folder with the date and time appended to the end. The default limit is 100 MB. Values lower than 100 kB will use 100 kB as the value instead.
-   <u>MaxLogFileCount</u>: A string specifying the maximum file count of log files. When the limit is hit, a new log is created in the same folder with the date and time appended to the end and the oldest log file will be deleted. Minimum supported value is 2. A value of 0 or a negative value indicates no limit on the count.

Once these properties are set, the connector populates the log file as it carries out various tasks, such as when authentication is performed or queries are executed. If the specified file doesn't already exist, it is created.

#### 5.3.2. Log Verbosity

The verbosity level determines the amount of detail that the connector reports to the

`Logfile`

. Supported

<u>Verbosity</u>

levels range from 1 to 5.

The following list describes each level:

<table><tbody><tr><td>1</td><td>Setting <u>Verbosity</u> to 1 logs the query, the number of rows returned by it, the start of execution and the time taken, and any errors.</td></tr><tr><td>2</td><td>Setting <u>Verbosity</u> to 2 logs everything included in <u>Verbosity</u> 1 and additional information about the request.</td></tr><tr><td>3</td><td>Setting <u>Verbosity</u> to 3 also logs the body of the request and the response.</td></tr><tr><td>4</td><td>Setting <u>Verbosity</u> to 4 also logs transport-level communication with the data source. This includes SSL negotiation.</td></tr><tr><td>5</td><td>Setting <u>Verbosity</u> to 5 also logs communication with the data source and additional details that may be helpful in troubleshooting problems. This includes interface commands.</td></tr></tbody></table>

For normal operations, <u>Verbosity</u> should not be set to greater than 1. At higher verbosities you can log substantial amounts of data, which can delay execution times.

To refine the logged content further by showing/hiding specific categories of information, see <u>LogModules</u>.

##### 5.3.2.1. Sensitive Data

Verbosity levels of 3 and higher may capture information that you do not want shared outside of your organization. The following lists information of concern for each level:

-   Verbosity 3: The full body of the request and the response, which includes all the data returned by the connector
-   Verbosity 4: SSL certificates
-   Verbosity 5: Any extra transfer data not included at Verbosity 3, such as non human-readable binary transfer data

**Note:** Although we mask sensitive values, such as passwords, in the connection string and any request in the log, it is always best practice to review the logs for any sensitive information before sharing outside your organization.

##### 5.3.2.2. Advanced Logging

You may want to refine the exact information that is recorded to the log file. This can be accomplished using the <u>LogModules</u> property. This property allows you to filter the logging using a semicolon-separated list of logging modules.

All modules are four characters long. **Note that modules containing three letters have a required trailing blank space**.

The available modules are:

-   **EXEC**: Query Execution. Includes execution messages for original SQL queries, parsed SQL queries, and normalized SQL queries. Query and page success/failure messages appear here as well.
-   **INFO**: General Information. Includes the connection string, driver version (build number), and initial connection messages.
-   **HTTP**: HTTP Protocol messages. Includes HTTP requests/responses (including POST messages), as well as Kerberos related messages.
-   **SSL** : SSL certificate messages.
-   **OAUT**: OAuth related failure/success messages.
-   **SQL** : Includes SQL transactions, SQL bulk transfer messages, and SQL result set messages.
-   **META**: Metadata cache and schema messages.
-   **TCP** : Incoming and Ongoing raw bytes on TCP transport layer messages.

Example property value:  

`LogModules=INFO;EXEC;SSL ;SQL ;META;`

Note that these modules refine the information as it is pulled in, after taking the <u>Verbosity</u> into account.




### 5.4. Stored Procedures

Stored procedures are function-like interfaces that extend the functionality of the connector beyond simple SELECT/INSERT/UPDATE/DELETE operations with Microsoft Access.

Stored procedures accept a list of parameters, perform their intended function, and then return any relevant response data from Microsoft Access, along with an indication of whether the procedure succeeded or failed.

Exports an existing table to an external Access database.

#### 5.4.1. Input

<table><tbody><tr><td><b>Name</b></td><td><b>Type</b></td><td><b>Description</b></td></tr><tr><td>TableName</td><td><i>String</i></td><td>Name of the table to export.</td></tr><tr><td>DatabaseName</td><td><i>String</i></td><td>Name of the destination database that the table will be exported to upon execution of this procedure.</td></tr><tr><td>CreateNew</td><td><i>String</i></td><td>Whether a new database file will be created upon execution of this procedure.<p>The allowed values are <i>Yes, No</i>.</p><p>The default value is <i>No</i>.</p></td></tr></tbody></table>

#### 5.4.2. Result Set Columns

<table><tbody><tr><td><b>Name</b></td><td><b>Type</b></td><td><b>Description</b></td></tr><tr><td>Status</td><td><i>String</i></td><td>Indicates whether the procedure was successful.</td></tr></tbody></table>



## 6. Data Model

The connector connects to Microsoft Access Database files stored locally on disk.

Microsoft Access tables are exposed as tables and query projections are exposed as read-only views.

Set `IncludeMSysTables` to true to include system tables in the list of discovered tables.


## 7. Connection String Options

The connection string properties are the various options that can be used to establish a connection. This section provides a complete list of the options you can configure in the connection string for this provider. Click the links for further details.

For more information on establishing a connection, see [Establishing a Connection](https://cdn.cdata.com/help/DCK/py/pg_connectionpy.htm).

**[Database](https://cdn.cdata.com/help/DCK/py/RSBAccess_c_Database.htm)**

___

<table><tbody><tr><td><b>Property</b></td><td><b>Description</b></td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_DataSource.htm">DataSource</a></td><td>The full path and name of the MS Access database file.</td></tr></tbody></table>

**[Logging](https://cdn.cdata.com/help/DCK/py/RSBAccess_c_Logging.htm)**

___

<table><tbody><tr><td><b>Property</b></td><td><b>Description</b></td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Logfile.htm">Logfile</a></td><td>A filepath which designates the name and location of the log file.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Verbosity.htm">Verbosity</a></td><td>The verbosity level that determines the amount of detail included in the log file.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_LogModules.htm">LogModules</a></td><td>Core modules to be included in the log file.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_MaxLogFileSize.htm">MaxLogFileSize</a></td><td>A string specifying the maximum size in bytes for a log file (for example, 10 MB).</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_MaxLogFileCount.htm">MaxLogFileCount</a></td><td>A string specifying the maximum file count of log files.</td></tr></tbody></table>

**[Schema](https://cdn.cdata.com/help/DCK/py/RSBAccess_c_Schema.htm)**

___

<table><tbody><tr><td><b>Property</b></td><td><b>Description</b></td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Location.htm">Location</a></td><td>A path to the directory that contains the schema files defining tables, views, and stored procedures.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_BrowsableSchemas.htm">BrowsableSchemas</a></td><td>This property restricts the schemas reported to a subset of the available schemas. For example, BrowsableSchemas=SchemaA,SchemaB,SchemaC.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Tables.htm">Tables</a></td><td>This property restricts the tables reported to a subset of the available tables. For example, Tables=TableA,TableB,TableC.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Views.htm">Views</a></td><td>Restricts the views reported to a subset of the available tables. For example, Views=ViewA,ViewB,ViewC.</td></tr></tbody></table>

**[Caching](https://cdn.cdata.com/help/DCK/py/RSBAccess_c_Caching.htm)**

___

<table><tbody><tr><td><b>Property</b></td><td><b>Description</b></td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_AutoCache.htm">AutoCache</a></td><td>Automatically caches the results of SELECT queries into a cache database specified by either CacheLocation or both of CacheConnection and CacheProvider .</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_CacheProvider.htm">CacheProvider</a></td><td>The name of the provider to be used to cache data.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_CacheDriver.htm">CacheDriver</a></td><td>The database driver used to cache data.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_CacheConnection.htm">CacheConnection</a></td><td>The connection string for the cache database. This property is always used in conjunction with CacheProvider . Setting both properties will override the value set for CacheLocation for caching data.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_CacheLocation.htm">CacheLocation</a></td><td>Specifies the path to the cache when caching to a file.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_CacheTolerance.htm">CacheTolerance</a></td><td>The tolerance for stale data in the cache specified in seconds when using AutoCache .</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Offline.htm">Offline</a></td><td>Use offline mode to get the data from the cache instead of the live source.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_CacheMetadata.htm">CacheMetadata</a></td><td>This property determines whether or not to cache the table metadata to a file store.</td></tr></tbody></table>

**[Miscellaneous](https://cdn.cdata.com/help/DCK/py/RSBAccess_c_Miscellaneous.htm)**

___

<table><tbody><tr><td><b>Property</b></td><td><b>Description</b></td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_CreateNewDatabase.htm">CreateNewDatabase</a></td><td>Specifies what format shoud be used by a new database file created when the file specified by connection property DataSource does not exist.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_IncludeMSysTables.htm">IncludeMSysTables</a></td><td>Set this property to the true value to allow querying from the system tables.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_MaxRows.htm">MaxRows</a></td><td>Limits the number of rows returned when no aggregation or GROUP BY is used in the query. LIMIT clauses take precedence over the limit specified in MaxRows.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Other.htm">Other</a></td><td>These hidden properties are used only in specific use cases.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Readonly.htm">Readonly</a></td><td>You can use this property to enforce read-only access to Microsoft Access from the provider.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_RTK.htm">RTK</a></td><td>The runtime key used for licensing.</td></tr></tbody></table>

### 7.1. Database

This section provides a complete list of the Database properties you can configure in the connection string for this provider.

#### 7.1.1. DataSource

The full path and name of the MS Access database file.

##### 7.1.1.1. Data Type

string

##### 7.1.1.2. Default Value

""

##### 7.1.1.3. Remarks

Note that encrypted Access databases are not currently supported; however, when you password-protect a database in the Microsoft Access GUI, you have the option to set a password without encrypting. If you have set a password for your database without also encrypting it, specifying the path to the database in this property is sufficient.

### 7.2. Logging

This section provides a complete list of the Logging properties you can configure in the connection string for this provider.

___

<table><tbody><tr><td><b>Property</b></td><td><b>Description</b></td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Logfile.htm">Logfile</a></td><td>A filepath which designates the name and location of the log file.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Verbosity.htm">Verbosity</a></td><td>The verbosity level that determines the amount of detail included in the log file.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_LogModules.htm">LogModules</a></td><td>Core modules to be included in the log file.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_MaxLogFileSize.htm">MaxLogFileSize</a></td><td>A string specifying the maximum size in bytes for a log file (for example, 10 MB).</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_MaxLogFileCount.htm">MaxLogFileCount</a></td><td>A string specifying the maximum file count of log files.</td></tr></tbody></table>

#### 7.2.1. Logfile

A filepath which designates the name and location of the log file.

##### 7.2.1.1. Data Type

string

##### 7.2.1.2. Default Value

""

##### 7.2.1.3. Remarks

Once this property is set, the connector will populate the log file as it carries out various tasks, such as when authentication is performed or queries are executed. If the specified file doesn't already exist, it will be created.

Connection strings and version information are also logged, though connection properties containing sensitive information are masked automatically.

If a relative filepath is supplied, the location of the log file will be resolved based on the path found in the [Location](https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Location.htm) connection property.

For more control over what is written to the log file, you can adjust the [Verbosity](https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Verbosity.htm) property.

Log contents are categorized into several modules. You can show/hide individual modules using the [LogModules](https://cdn.cdata.com/help/DCK/py/RSBAccess_p_LogModules.htm) property.

To edit the maximum size of a single logfile before a new one is created, see [MaxLogFileSize](https://cdn.cdata.com/help/DCK/py/RSBAccess_p_MaxLogFileSize.htm).

If you would like to place a cap on the number of logfiles generated, use [MaxLogFileCount](https://cdn.cdata.com/help/DCK/py/RSBAccess_p_MaxLogFileCount.htm).
 
#### 7.2.2. Verbosity

The verbosity level determines the amount of detail that the connector reports to the Logfile. Verbosity levels from 1 to 5 are supported. These are detailed in the Logging page.
  * **Data Type:** string
  * **Default Value:** "1"

#### 7.2.3. LogModules
 
Core modules to be included in the log file. Only the modules specified (separated by ';') will be included in the log file. By default all modules are included.
  * **Data Type:** string
  * **Default Value:** ""
 
#### 7.2.4. MaxLogFileSize
 
A string specifying the maximum size in bytes for a log file (for example, 10 MB). When the limit is hit, a new log is created in the same folder with the date and time appended to the end. The default limit is 100 MB. Values lower than 100 kB will use 100 kB as the value instead.
  * **Data Type:** string
  * **Default Value:** "100MB"
 
#### 7.2.5. MaxLogFileCount
 
A string specifying the maximum file count of log files. When the limit is hit, a new log is created in the same folder with the date and time appended to the end and the oldest log file will be deleted. The minimum supported value is 2. A value of 0 or a negative value indicates no limit on the count.
  * **Data Type:** int
  * **Default Value:** -1
 
### 7.3. Schema

This section provides a complete list of the Schema properties you can configure in the connection string for this provider.

___

<table><tbody><tr><td><b>Property</b></td><td><b>Description</b></td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Location.htm">Location</a></td><td>A path to the directory that contains the schema files defining tables, views, and stored procedures.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_BrowsableSchemas.htm">BrowsableSchemas</a></td><td>This property restricts the schemas reported to a subset of the available schemas. For example, BrowsableSchemas=SchemaA,SchemaB,SchemaC.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Tables.htm">Tables</a></td><td>This property restricts the tables reported to a subset of the available tables. For example, Tables=TableA,TableB,TableC.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Views.htm">Views</a></td><td>Restricts the views reported to a subset of the available tables. For example, Views=ViewA,ViewB,ViewC.</td></tr></tbody></table>

#### 7.3.1. Location

A path to the directory that contains the schema files for the connector defining tables, views, and stored procedures (.rsd files for tables and views, .rsb files for stored procedures). The folder location can be a relative path from the location of the executable. The <u>Location</u> property is only needed if you want to customize definitions (for example, change a column name, ignore a column, and so on) or extend the data model with new tables, views, or stored procedures.
  * **Data Type:** string
  * **Default Value:** `"%APPDATA%\\\\CData\\\\Access Data Provider\\\\Schema"`

If left unspecified, the default location is "%APPDATA%\\\\CData\\\\Access Data Provider\\\\Schema" with **%APPDATA%** being set to the user's configuration directory:

<table><tbody><tr><td><b>Platform</b></td><td><b>%APPDATA%</b></td></tr><tr><td>Windows</td><td>The value of the APPDATA environment variable</td></tr><tr><td>Linux</td><td>~/.config</td></tr></tbody></table>


#### ****7.3.2. BrowsableSchemas

This property restricts the schemas reported to a subset of the available schemas. For example, BrowsableSchemas=SchemaA,SchemaB,SchemaC.

Data Type
string

Default Value
""

Remarks
Listing the schemas from databases can be expensive. Providing a list of schemas in the connection string improves the performance.

#### ****7.3.3. Tables

This property restricts the tables reported to a subset of the available tables. For example, Tables=TableA,TableB,TableC.

Data Type
string

Default Value
""

Remarks
Listing the tables from some databases can be expensive. Providing a list of tables in the connection string improves the performance of the connector.

This property can also be used as an alternative to automatically listing views if you already know which ones you want to work with and there would otherwise be too many to work with.

Specify the tables you want in a comma-separated list. Each table should be a valid SQL identifier with any special characters escaped using square brackets, double-quotes or backticks. For example, Tables=TableA,[TableB/WithSlash],WithCatalog.WithSchema.`TableC With Space`.

Note that when connecting to a data source with multiple schemas or catalogs, you will need to provide the fully qualified name of the table in this property, as in the last example here, to avoid ambiguity between tables that exist in multiple catalogs or schemas.

#### ****7.3.4. Views

Restricts the views reported to a subset of the available tables. For example, Views=ViewA,ViewB,ViewC.

Data Type
string

Default Value
""

Remarks
Listing the views from some databases can be expensive. Providing a list of views in the connection string improves the performance of the connector.

This property can also be used as an alternative to automatically listing views if you already know which ones you want to work with and there would otherwise be too many to work with.

Specify the views you want in a comma-separated list. Each view should be a valid SQL identifier with any special characters escaped using square brackets, double-quotes or backticks. For example, Views=ViewA,[ViewB/WithSlash],WithCatalog.WithSchema.`ViewC With Space`.

Note that when connecting to a data source with multiple schemas or catalogs, you will need to provide the fully qualified name of the table in this property, as in the last example here, to avoid ambiguity between tables that exist in multiple catalogs or schemas.

### 7.4. Caching

This section provides a complete list of the Caching properties you can configure in the connection string for this provider.

___

<table><tbody><tr><td><b>Property</b></td><td><b>Description</b></td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_AutoCache.htm">AutoCache</a></td><td>Automatically caches the results of SELECT queries into a cache database specified by either CacheLocation or both of CacheConnection and CacheProvider .</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_CacheProvider.htm">CacheProvider</a></td><td>The name of the provider to be used to cache data.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_CacheDriver.htm">CacheDriver</a></td><td>The database driver used to cache data.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_CacheConnection.htm">CacheConnection</a></td><td>The connection string for the cache database. This property is always used in conjunction with CacheProvider . Setting both properties will override the value set for CacheLocation for caching data.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_CacheLocation.htm">CacheLocation</a></td><td>Specifies the path to the cache when caching to a file.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_CacheTolerance.htm">CacheTolerance</a></td><td>The tolerance for stale data in the cache specified in seconds when using AutoCache .</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_Offline.htm">Offline</a></td><td>Use offline mode to get the data from the cache instead of the live source.</td></tr><tr><td><a href="https://cdn.cdata.com/help/DCK/py/RSBAccess_p_CacheMetadata.htm">CacheMetadata</a></td><td>This property determines whether or not to cache the table metadata to a file store.</td></tr></tbody></table>

#### ****7.4.1. AutoCache

Automatically caches the results of SELECT queries into a cache database specified by either CacheLocation or both of CacheConnection and CacheProvider .

Data Type
bool

Default Value
false

Remarks
When AutoCache = true, the connector automatically maintains a cache of your table's data in the database of your choice.


#### 7.4.2. CacheProvider



#### 7.4.3. CacheDriver



#### 7.4.4. CacheConnection



#### 7.4.5. CacheLocation



#### 7.4.6. CacheTolerance



#### 7.4.7. Offline



#### 7.4.8. CacheMetadata



### 7.5. Miscellaneous



#### 7.5.1. CreateNewDatabase



#### 7.5.2. IncludeMSysTables



#### 7.5.3. MaxRows



#### 7.5.4. Other



#### 7.5.5. Readonly



#### 7.5.6. RTK









